{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Dataset alicorn_twilight.csv\n",
    "Sebelum masuk ke tahap pembuatan model klasifikasi, dataset harus dilakukan preprocessing dulu seperti menghapus tanda spesial, mengubah menjadi huruf kecil, menghapus spasi double dan lain-lain.\n",
    "Dataset yang digunakan adalah dataset yang berisi kurang lebih 500 tweet tentang komentar orang-orang terhadap peristiwa berubahnya Twilight Sparkle menjadi Alicorn di akhir season 3 dari acara My Little Pony: Friendship is Magic. Dataset ini didapat dari crawling data di twitter menggunakan tools yang disediakan oleh Helmi Satria (Big thanks to him)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Membaca Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 507 entries, 0 to 506\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   conversation_id_str      507 non-null    int64 \n",
      " 1   created_at               507 non-null    object\n",
      " 2   favorite_count           507 non-null    int64 \n",
      " 3   full_text                507 non-null    object\n",
      " 4   id_str                   507 non-null    int64 \n",
      " 5   image_url                44 non-null     object\n",
      " 6   in_reply_to_screen_name  154 non-null    object\n",
      " 7   lang                     507 non-null    object\n",
      " 8   location                 335 non-null    object\n",
      " 9   quote_count              507 non-null    int64 \n",
      " 10  reply_count              507 non-null    int64 \n",
      " 11  retweet_count            507 non-null    int64 \n",
      " 12  tweet_url                507 non-null    object\n",
      " 13  user_id_str              507 non-null    int64 \n",
      " 14  username                 507 non-null    object\n",
      "dtypes: int64(7), object(8)\n",
      "memory usage: 59.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   conversation_id_str                      created_at  favorite_count  \\\n",
       " 0   349251986438356994  Mon Jun 24 19:45:37 +0000 2013               0   \n",
       " 1   349044033647157248  Mon Jun 24 06:06:31 +0000 2013               0   \n",
       " 2   348985526667329537  Mon Jun 24 02:08:49 +0000 2013               0   \n",
       " 3   348932366217121793  Sun Jun 23 22:35:33 +0000 2013               0   \n",
       " 4   348913737111048192  Sun Jun 23 21:21:32 +0000 2013               0   \n",
       " \n",
       "                                            full_text              id_str  \\\n",
       " 0  @MLP_Alicorn_Twi oh hi twilight how r u and th...  349251986438356994   \n",
       " 1  @NerdyPinkie that s great what have you been u...  349045855346638849   \n",
       " 2  @NEligahn @BlameLoomy @TailsTheBard @PhotoPwne...  348986036539506688   \n",
       " 3  @MLP_Alicorn_Twi u ok twilight? *looks conserned*  348932366217121793   \n",
       " 4           @MLP_Alicorn_Twi oh hi Twilight how r u?  348913737111048192   \n",
       " \n",
       "   image_url in_reply_to_screen_name lang                   location  \\\n",
       " 0       NaN         MLP_Alicorn_Twi   en             Leeds, England   \n",
       " 1       NaN             NerdyPinkie   en                        NaN   \n",
       " 2       NaN                NEligahn   en  The Grand Ovation Theater   \n",
       " 3       NaN         MLP_Alicorn_Twi   en             Leeds, England   \n",
       " 4       NaN         MLP_Alicorn_Twi   en             Leeds, England   \n",
       " \n",
       "    quote_count  reply_count  retweet_count  \\\n",
       " 0            0            2              0   \n",
       " 1            0            1              0   \n",
       " 2            0            0              0   \n",
       " 3            0            1              0   \n",
       " 4            0            1              0   \n",
       " \n",
       "                                            tweet_url  user_id_str  \\\n",
       " 0  https://x.com/Shelton20_Jack/status/3492519864...    906748764   \n",
       " 1  https://x.com/Bronywho_/status/349045855346638849   1542576176   \n",
       " 2  https://x.com/Grimrubix/status/348986036539506688    614900888   \n",
       " 3  https://x.com/Shelton20_Jack/status/3489323662...    906748764   \n",
       " 4  https://x.com/Shelton20_Jack/status/3489137371...    906748764   \n",
       " \n",
       "          username  \n",
       " 0  Shelton20_Jack  \n",
       " 1       Bronywho_  \n",
       " 2       Grimrubix  \n",
       " 3  Shelton20_Jack  \n",
       " 4  Shelton20_Jack  ,\n",
       " None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'alicorn_twilight.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "dataset.head(), dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MLP_Alicorn_Twi oh hi twilight how r u and th...</td>\n",
       "      <td>oh hi twilight how r u and the other ponys in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@NerdyPinkie that s great what have you been u...</td>\n",
       "      <td>that s great what have you been up to Did you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@NEligahn @BlameLoomy @TailsTheBard @PhotoPwne...</td>\n",
       "      <td>As in Cadance is dead Twilights not an alicorn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@MLP_Alicorn_Twi u ok twilight? *looks conserned*</td>\n",
       "      <td>u ok twilight looks conserned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@MLP_Alicorn_Twi oh hi Twilight how r u?</td>\n",
       "      <td>oh hi Twilight how r u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  @MLP_Alicorn_Twi oh hi twilight how r u and th...   \n",
       "1  @NerdyPinkie that s great what have you been u...   \n",
       "2  @NEligahn @BlameLoomy @TailsTheBard @PhotoPwne...   \n",
       "3  @MLP_Alicorn_Twi u ok twilight? *looks conserned*   \n",
       "4           @MLP_Alicorn_Twi oh hi Twilight how r u?   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  oh hi twilight how r u and the other ponys in ...  \n",
       "1  that s great what have you been up to Did you ...  \n",
       "2  As in Cadance is dead Twilights not an alicorn...  \n",
       "3                      u ok twilight looks conserned  \n",
       "4                             oh hi Twilight how r u  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Fungsi untuk cleaning text\n",
    "def clean_text(text):\n",
    "    # Menghapus URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    # Menghapus mention dan hashtag\n",
    "    text = re.sub(r\"@\\w+|#\\w+\", \"\", text)\n",
    "    # Menghapus tanda baca\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    # Menghapus angka\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    # Menghapus whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# Terapkan fungsi clean_text ke dataset['full_text']\n",
    "dataset['cleaned_text'] = dataset['full_text'].apply(clean_text)\n",
    "\n",
    "# Tampilkan kolom full_text dan cleaned_text\n",
    "dataset[['full_text', 'cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Case Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh hi twilight how r u and the other ponys in ...</td>\n",
       "      <td>oh hi twilight how r u and the other ponys in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that s great what have you been up to Did you ...</td>\n",
       "      <td>that s great what have you been up to did you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As in Cadance is dead Twilights not an alicorn...</td>\n",
       "      <td>as in cadance is dead twilights not an alicorn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u ok twilight looks conserned</td>\n",
       "      <td>u ok twilight looks conserned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh hi Twilight how r u</td>\n",
       "      <td>oh hi twilight how r u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  \\\n",
       "0  oh hi twilight how r u and the other ponys in ...   \n",
       "1  that s great what have you been up to Did you ...   \n",
       "2  As in Cadance is dead Twilights not an alicorn...   \n",
       "3                      u ok twilight looks conserned   \n",
       "4                             oh hi Twilight how r u   \n",
       "\n",
       "                                     normalized_text  \n",
       "0  oh hi twilight how r u and the other ponys in ...  \n",
       "1  that s great what have you been up to did you ...  \n",
       "2  as in cadance is dead twilights not an alicorn...  \n",
       "3                      u ok twilight looks conserned  \n",
       "4                             oh hi twilight how r u  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ubah teks menjadi lowercase\n",
    "dataset['normalized_text'] = dataset['cleaned_text'].str.lower()\n",
    "\n",
    "# Tampilkan kolom cleaned_text dan normalized_text\n",
    "dataset[['cleaned_text', 'normalized_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>no_stopwords_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh hi twilight how r u and the other ponys in ...</td>\n",
       "      <td>oh hi twilight r u ponys ponyville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that s great what have you been up to did you ...</td>\n",
       "      <td>great hear twilight filly interesting alicorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as in cadance is dead twilights not an alicorn...</td>\n",
       "      <td>cadance dead twilights alicorn show characters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u ok twilight looks conserned</td>\n",
       "      <td>u ok twilight looks conserned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh hi twilight how r u</td>\n",
       "      <td>oh hi twilight r u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     normalized_text  \\\n",
       "0  oh hi twilight how r u and the other ponys in ...   \n",
       "1  that s great what have you been up to did you ...   \n",
       "2  as in cadance is dead twilights not an alicorn...   \n",
       "3                      u ok twilight looks conserned   \n",
       "4                             oh hi twilight how r u   \n",
       "\n",
       "                                   no_stopwords_text  \n",
       "0                 oh hi twilight r u ponys ponyville  \n",
       "1      great hear twilight filly interesting alicorn  \n",
       "2  cadance dead twilights alicorn show characters...  \n",
       "3                      u ok twilight looks conserned  \n",
       "4                                 oh hi twilight r u  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download stopwords jika belum tersedia\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Atur bahasa yang digunakan\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Fungsi untuk menghapus stopwords\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "# Terapkan fungsi remove_stopwords ke dataset['normalized_text']\n",
    "dataset['no_stopwords_text'] = dataset['normalized_text'].apply(remove_stopwords)\n",
    "\n",
    "# Tampilkan kolom normalized_text dan no_stopwords_text\n",
    "dataset[['normalized_text', 'no_stopwords_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_stopwords_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh hi twilight r u ponys ponyville</td>\n",
       "      <td>[oh, hi, twilight, r, u, ponys, ponyville]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great hear twilight filly interesting alicorn</td>\n",
       "      <td>[great, hear, twilight, filly, interesting, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cadance dead twilights alicorn show characters...</td>\n",
       "      <td>[cadance, dead, twilights, alicorn, show, char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u ok twilight looks conserned</td>\n",
       "      <td>[u, ok, twilight, looks, conserned]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh hi twilight r u</td>\n",
       "      <td>[oh, hi, twilight, r, u]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   no_stopwords_text  \\\n",
       "0                 oh hi twilight r u ponys ponyville   \n",
       "1      great hear twilight filly interesting alicorn   \n",
       "2  cadance dead twilights alicorn show characters...   \n",
       "3                      u ok twilight looks conserned   \n",
       "4                                 oh hi twilight r u   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0         [oh, hi, twilight, r, u, ponys, ponyville]  \n",
       "1  [great, hear, twilight, filly, interesting, al...  \n",
       "2  [cadance, dead, twilights, alicorn, show, char...  \n",
       "3                [u, ok, twilight, looks, conserned]  \n",
       "4                           [oh, hi, twilight, r, u]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download tokenizer jika belum tersedia\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Fungsi untuk tokenisasi teks\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Ubah list of tokens menjadi string\n",
    "def list_to_string(token_list):\n",
    "    return \" \".join(token_list)\n",
    "\n",
    "# Terapkan fungsi tokenize_text ke dataset['no_stopwords_text']\n",
    "dataset['tokenized_text'] = dataset['no_stopwords_text'].apply(tokenize_text)\n",
    "\n",
    "# Tampilkan kolom no_stopwords_text dan tokenized_text\n",
    "dataset[['no_stopwords_text', 'tokenized_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[oh, hi, twilight, r, u, ponys, ponyville]</td>\n",
       "      <td>[oh, hi, twilight, r, u, pony, ponyville]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[great, hear, twilight, filly, interesting, al...</td>\n",
       "      <td>[great, hear, twilight, filly, interesting, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[cadance, dead, twilights, alicorn, show, char...</td>\n",
       "      <td>[cadance, dead, twilight, alicorn, show, chara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[u, ok, twilight, looks, conserned]</td>\n",
       "      <td>[u, ok, twilight, look, conserned]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[oh, hi, twilight, r, u]</td>\n",
       "      <td>[oh, hi, twilight, r, u]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      tokenized_text  \\\n",
       "0         [oh, hi, twilight, r, u, ponys, ponyville]   \n",
       "1  [great, hear, twilight, filly, interesting, al...   \n",
       "2  [cadance, dead, twilights, alicorn, show, char...   \n",
       "3                [u, ok, twilight, looks, conserned]   \n",
       "4                           [oh, hi, twilight, r, u]   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0          [oh, hi, twilight, r, u, pony, ponyville]  \n",
       "1  [great, hear, twilight, filly, interesting, al...  \n",
       "2  [cadance, dead, twilight, alicorn, show, chara...  \n",
       "3                 [u, ok, twilight, look, conserned]  \n",
       "4                           [oh, hi, twilight, r, u]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Inisialisasi WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Fungsi untuk lemmatization\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# Terapkam fungsi lemmatize_tokens ke dataset['tokenized_text']\n",
    "dataset['lemmatized_text'] = dataset['tokenized_text'].apply(lemmatize_tokens)\n",
    "\n",
    "# Tampilkan kolom tokenized_text dan lemmatized_text\n",
    "dataset[['tokenized_text', 'lemmatized_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Handle Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_as_string</th>\n",
       "      <th>no_emojis_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh hi twilight r u pony ponyville</td>\n",
       "      <td>oh hi twilight r u pony ponyville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great hear twilight filly interesting alicorn</td>\n",
       "      <td>great hear twilight filly interesting alicorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cadance dead twilight alicorn show character d...</td>\n",
       "      <td>cadance dead twilight alicorn show character d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u ok twilight look conserned</td>\n",
       "      <td>u ok twilight look conserned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh hi twilight r u</td>\n",
       "      <td>oh hi twilight r u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_as_string  \\\n",
       "0                  oh hi twilight r u pony ponyville   \n",
       "1      great hear twilight filly interesting alicorn   \n",
       "2  cadance dead twilight alicorn show character d...   \n",
       "3                       u ok twilight look conserned   \n",
       "4                                 oh hi twilight r u   \n",
       "\n",
       "                                      no_emojis_text  \n",
       "0                  oh hi twilight r u pony ponyville  \n",
       "1      great hear twilight filly interesting alicorn  \n",
       "2  cadance dead twilight alicorn show character d...  \n",
       "3                       u ok twilight look conserned  \n",
       "4                                 oh hi twilight r u  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Ubah list of tokens menjadi string\n",
    "def list_to_string(token_list):\n",
    "    return \" \".join(token_list)\n",
    "\n",
    "# Fungsi untuk menghapus emoji\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                           u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                           u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                           u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                           u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                           u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                           u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                           u\"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Terapkan fungsi list_to_string ke dataset['lemmatized_text']\n",
    "dataset['text_as_string'] = dataset['lemmatized_text'].apply(list_to_string)\n",
    "\n",
    "# Terapkam fungsi remove_emojis ke dataset['text_as_string']\n",
    "dataset['no_emojis_text'] = dataset['text_as_string'].apply(remove_emojis)\n",
    "\n",
    "# Display a few rows to verify\n",
    "dataset[['text_as_string', 'no_emojis_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Handle Slang Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_emojis_text</th>\n",
       "      <th>no_slang_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh hi twilight r u pony ponyville</td>\n",
       "      <td>oh hi twilight are you pony ponyville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great hear twilight filly interesting alicorn</td>\n",
       "      <td>great hear twilight filly interesting alicorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cadance dead twilight alicorn show character d...</td>\n",
       "      <td>cadance dead twilight alicorn show character d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u ok twilight look conserned</td>\n",
       "      <td>you ok twilight look conserned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh hi twilight r u</td>\n",
       "      <td>oh hi twilight are you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      no_emojis_text  \\\n",
       "0                  oh hi twilight r u pony ponyville   \n",
       "1      great hear twilight filly interesting alicorn   \n",
       "2  cadance dead twilight alicorn show character d...   \n",
       "3                       u ok twilight look conserned   \n",
       "4                                 oh hi twilight r u   \n",
       "\n",
       "                                       no_slang_text  \n",
       "0              oh hi twilight are you pony ponyville  \n",
       "1      great hear twilight filly interesting alicorn  \n",
       "2  cadance dead twilight alicorn show character d...  \n",
       "3                     you ok twilight look conserned  \n",
       "4                             oh hi twilight are you  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definisikan slang dictionary\n",
    "slang_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"r\": \"are\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"lol\": \"laughing out loud\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"nvm\": \"never mind\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"ikr\": \"I know right\",\n",
    "    \"bff\": \"best friends forever\",\n",
    "    \"afk\": \"away from keyboard\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"imho\": \"in my humble opinion\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"pls\": \"please\",\n",
    "    \"k\": \"okay\",\n",
    "    \"ye\": \"yes\",\n",
    "    \"nah\": \"no\",\n",
    "    \"cya\": \"see you\",\n",
    "    \"luv\": \"love\",\n",
    "    \"b4\": \"before\",\n",
    "    \"h8\": \"hate\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"w8\": \"wait\",\n",
    "    \"yolo\": \"you only live once\",\n",
    "    \"wtf\": \"what the fuck\",\n",
    "    \"wyd\": \"what are you doing\",\n",
    "    \"wya\": \"where are you at\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"ppl\": \"people\",\n",
    "    \"msg\": \"message\",\n",
    "    \"bday\": \"birthday\",\n",
    "    \"hmu\": \"hit me up\",\n",
    "    \"bae\": \"before anyone else\",\n",
    "    \"fam\": \"family or close friends\",\n",
    "    \"lit\": \"amazing or fun\",\n",
    "    \"dope\": \"cool\",\n",
    "    \"noob\": \"beginner or newbie\",\n",
    "    \"gg\": \"good game\",\n",
    "    \"ty\": \"thank you\",\n",
    "    \"dm\": \"direct message\",\n",
    "    \"rn\": \"right now\",\n",
    "    \"tho\": \"though\",\n",
    "    \"idc\": \"I don't care\",\n",
    "    \"ily\": \"I love you\",\n",
    "    # Tambahkan lebih banyak slang sesuai kebutuhan\n",
    "}\n",
    "\n",
    "# Fungsi untuk mengganti slang dengan kamus yang sudah didefinisi\n",
    "def replace_slang(text, slang_dict):\n",
    "    words = text.split()\n",
    "    replaced_words = [slang_dict[word] if word in slang_dict else word for word in words]\n",
    "    return \" \".join(replaced_words)\n",
    "\n",
    "# Terapkan hasil ke kolom 'no_emojis_text'\n",
    "dataset['no_slang_text'] = dataset['no_emojis_text'].apply(lambda x: replace_slang(x, slang_dict))\n",
    "\n",
    "# Tampilkan kolom 'no_emojis_text' dan 'no_slang_text'\n",
    "dataset[['no_emojis_text', 'no_slang_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Ekspor Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset berhasil diekspor ke: processed_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "# Ganti nama kolom 'no_slang_text' menjadi 'full_text'\n",
    "dataset['full_text'] = dataset['no_slang_text']\n",
    "\n",
    "# Hapus kolom yang tidak diperlukan\n",
    "dataset = dataset[['conversation_id_str', 'created_at', 'favorite_count', 'full_text', 'id_str', 'image_url', 'in_reply_to_screen_name', 'lang', 'location', 'quote_count', 'reply_count', 'retweet_count', 'tweet_url', 'user_id_str', 'username']]\n",
    "\n",
    "# Ekspor dataset yang sudah diproses ke file CSV\n",
    "output_file_path = 'processed_tweets.csv'\n",
    "dataset.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Dataset berhasil diekspor ke: {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
